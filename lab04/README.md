## Lab 04

The fourth lab is divided into two parts:
- CLM: this part uses causal language modeling (CLM) to generate new sequences of tokens. You will use GPT-2 to generate new sequences of tokens. In particular, you will first fine-tune the model on a medical text dataset. Then, you will use the fine-tuned model to generate new sequences of tokens that are (somewhat) coherent with the medical domain.

- LLMs: this part focuses on using various LLMs (Llama 3.2, and Mistral v0.2). You will see how we can use instruction-tuned versions of those models to get coherent answers to various questions. 

The following are the files you will use for this lab:
- CLM exercise ([text](./text-01-clm.ipynb)) ([solution](./solution-01-clm.ipynb))
- LLMs exercise ([text](./text-02-llms.ipynb)) ([solution](./solution-02-llms.ipynb))
