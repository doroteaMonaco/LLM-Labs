{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Analyzing thresholds\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation used to evaluate the performance of binary classification models. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
    "\n",
    "### Step 1: Generating some random data\n",
    "\n",
    "We simulate the result of the application of an LLM by generating two random vectors, of actual results and expected results (the ground truth). For this simplified example, the corresponding actual vector is always in the same place as the expected vector (it will not be always like this!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "# Step 1: Generate random dataset (100 vectors, each of 100 dimensions)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "expected = \"\"\n",
    "\n",
    "\n",
    "#we define here a perturbation factor to simulate the difference between the expected and the actual ones\n",
    "perturbation_factor = 1\n",
    "\n",
    "#the actual are defined in this way\n",
    "actual = \"\"\n",
    "\n",
    "# Print out the original and modified datasets for comparison\n",
    "print(\" (First 2 Vectors):\")\n",
    "print(expected[:2])\n",
    "print(\"\\nModified Data2 (First 2 Vectors):\")\n",
    "print(actual[:2])\n",
    "\n",
    "#the comparisons can be made as usual through cosine similarity\n",
    "cos_sim_matrix = cosine_similarity(actual, expected)\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cos_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: a function to compute TPR and FPR\n",
    "\n",
    "True Positive Rate (TPR), also called Sensitivity or Recall, is the proportion of actual positives that are correctly identified by the model. It is given by TPR = TP / (TP + FN), where TP = true positives; FN = False Negatives.\n",
    "\n",
    "False Positive Rate (FPR) is the proportion of actual negatives that are incorrectly classified as positives. It is given by FPR = FP / (FP + TN), where FP = False Positives, TN = True Negatives.\n",
    "\n",
    "A classifier typically outputs a probability score for each sample (the likelihood that a sample belongs to the positive class). To classify the sample, you apply a threshold on this score. If the score is above the threshold, the sample is classified as positive (class 1), and if it is below the threshold, it is classified as negative (class 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (TPR): 0\n",
      "False Positive Rate (FPR): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#a function to compute tpr and fpr given a vector of actual data, a vector of expected data, and a threshold\n",
    "\n",
    "def compute_tpr_fpr(data, data2, threshold=0.9):\n",
    "\n",
    "    # Compute the cosine similarity between all pairs of vectors\n",
    "    cos_sim_matrix = \"\"\n",
    "    \n",
    "    # Initialize counters for TP, FP, TN, FN\n",
    "    tp = 0  # True Positives\n",
    "    fp = 0  # False Positives\n",
    "    tn = 0  # True Negatives\n",
    "    fn = 0  # False Negatives\n",
    "    \n",
    "    # Loop over all the pairs in the matrix\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data2)):\n",
    "            # Check ground truth - vectors from the same index in original data\n",
    "                \n",
    "            # Apply the threshold to classify cosine similarity\n",
    "                \n",
    "            # Update the counts based on comparison of ground truth and prediction\n",
    "            pass\n",
    "\n",
    "    #compute tpr and fpr\n",
    "    tpr = 0\n",
    "    fpr = 0\n",
    "\n",
    "    return tpr, fpr\n",
    "\n",
    "#an example of computation for a threshold equal to 0.95\n",
    "tpr, fpr = compute_tpr_fpr(actual, expected, threshold=0.95)\n",
    "\n",
    "# Print the result\n",
    "print(f\"True Positive Rate (TPR): {tpr}\")\n",
    "print(f\"False Positive Rate (FPR): {fpr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Plotting the ROC curve\n",
    "\n",
    "In the ROC curve:\n",
    "\n",
    "- The x-axis represents the False Positive Rate (FPR)\n",
    "- The y-axis represents the True Positive Rate (TPR)\n",
    "\n",
    "Each point on the ROC curve corresponds to a specific threshold value. By adjusting the threshold, you change the trade-off between TPR and FPR.\n",
    "\n",
    "### Thresholding\n",
    "\n",
    "By varying this threshold from 0 to 1, you can calculate different values for TPR and FPR, generating a curve. The threshold determines the sensitivity (TPR) and the specificity (FPR) of the classifier:\n",
    "\n",
    "- At a high threshold, the model will classify fewer instances as positive, leading to fewer true positives and possibly many false negatives.\n",
    "\n",
    "- At a low threshold, the model will classify more instances as positive, leading to more true positives but also increasing false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TPR and FPR at varying thresholds\n",
    "thresholds = []  # Create 100 thresholds between 0 and 1\n",
    "tprs = []\n",
    "fprs = []\n",
    "\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprs, tprs, color='blue', label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Random guess line (diagonal)\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate AUC (Area Under Curve)\n",
    "roc_auc = auc(fprs, tprs)\n",
    "print(f'Area Under the ROC Curve (AUC): {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now reason about the following points:\n",
    "\n",
    "- What happens by varying the size of the vectors?\n",
    "- What happens by varying the perturbation factor?\n",
    "- How to cope with cases in which *we don't know* what is the ground truth (i.e., we don't know that the actual result correspond to the one in the same position in the expected results?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 2: A simple router architecture\n",
    "\n",
    "In this architecture, we leverage a Large Language Model (LLM) to dynamically interpret user instructions and route them to the appropriate task-specific prompt. This approach ensures that complex software engineering tasks, such as generating use cases or class diagrams, are efficiently handled based on the user's needs.\n",
    "\n",
    "The architecture is split into two main stages:\n",
    "\n",
    "- Router LLM Stage:\n",
    "  - The LLM analyzes the user's instruction and determines whether the task is related to generating use cases or a class diagram.\n",
    "  - It outputs an instruction to route the next stage.\n",
    "\n",
    "- Task Execution LLM Stage:\n",
    "  - Based on the generated prompt from the router, the LLM executes the required task by producing either:\n",
    "    - A set of use cases, or\n",
    "    - A UML class diagram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code for llama prompting\n",
    " \n",
    " \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#we define a method to ask any prompt to llama\n",
    "def ask_llama(prompt, maxl=200, temp=0.7):\n",
    "    \"\"\"\n",
    "    Send a prompt to the Llama model and get a response.\n",
    "\n",
    "    Args:\n",
    "    - prompt (str): The input question or statement to the model.\n",
    "    - max_length (int): The maximum length of the response.\n",
    "    - temperature (float): Controls randomness in the model's output.\n",
    "\n",
    "    Returns:\n",
    "    - str: The model's generated response.\n",
    "    \"\"\"\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    inputs.to(device)\n",
    "\n",
    "    # Generate the output\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],  # Tokenized input\n",
    "        max_length=maxl,         # Limit response length to avoid extra text\n",
    "        temperature=temp,        # Lower temperature to reduce randomness\n",
    "        do_sample=True,        # Disable sampling for deterministic output\n",
    "        pad_token_id=tokenizer.eos_token_id  # Ensure the model doesn't go beyond the end token\n",
    "    )\n",
    "\n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# Example usage\n",
    "prompt = \"\"\"\n",
    "System: You are an expert on world capitals.\n",
    "Respond with only the capital city of the given country. Do not repeat the question.\n",
    "\n",
    "Query: What is the capital of France?\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = ask_llama(prompt)\n",
    "\n",
    "print(f\"Prompt: {prompt}\\nResponse: {response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Router LLM - Decide the next step\n",
    "The first LLM will analyze the user's instruction and generate an instruction for the next prompt to use. For simplicity, in this case the router will only decide what is the type of diagram to create:\n",
    "\n",
    "- Use Case Diagram\n",
    "- Class Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_text = \"The proposed platform is designed to enhance the hiking experience for various user groups, including visitors, local guides, platform managers, and hut workers. The platform provides a centralized repository of hiking routes, hut information, and parking facilities. It also enables interactive features such as real-time hike tracking, personalized recommendations, and group hike planning. By combining these capabilities, the platform seeks to foster safe, informed, and collaborative hiking experiences.\\\n",
    "The platform will be deployed as a cloud-based web and mobile application accessible to all stakeholders. The distribution strategy includes an app available on major mobile operating systems, such as iOS and Android, alongside a responsive web interface. It will require an internet connection for features like real-time tracking, notifications, and user authentication, though some offline capabilities, such as pre-downloaded hike information, will also be available.\\\n",
    "User authentication will be role-based, ensuring that only authorized users, such as verified hut workers and platform managers, can access sensitive or administrative features.\\\n",
    "Visitors are the primary users of the platform. They can browse a comprehensive list of hiking trails, filter them based on specific criteria such as difficulty, length, or starting point, and view detailed descriptions. To access advanced features like personalized recommendations, visitors can create user accounts by registering on the platform. Registered users can record their fitness parameters, enabling the system to suggest trails tailored to their capabilities.\\\n",
    "During a hike, visitors can record their progress by marking reference points and sharing their live location through a broadcasting URL. They can also initiate group activities by planning hikes, adding group members, and confirming group participation. The platform allows visitors to start, terminate, and track their hikes, with notifications for unfinished hikes or late group members to ensure safety and accountability.\\\n",
    "Local guides enrich the platform by contributing essential information. They can add detailed descriptions of hikes, parking facilities, and huts, ensuring hikers have accurate and comprehensive data. Local guides also link parking lots and huts to specific trails as starting or arrival points, enhancing the planning process.\\\n",
    "To aid in the visual representation and accessibility of information, local guides can upload pictures of huts and connect these locations directly to hikes. This integration simplifies route planning and helps visitors visualize their journey.\\\n",
    "Platform managers oversee the operational integrity and safety of the platform. They verify new hut worker registrations, ensuring that only authorized personnel can update hut-related data. Managers can also broadcast weather alerts for specific areas, notifying all hikers in those regions through push notifications. This ensures that users stay informed about potentially hazardous conditions.\\\n",
    "The platform manager's role includes maintaining an organized and secure user system while facilitating collaboration between local guides, hut workers, and visitors.\\\n",
    "Hut workers are critical to the maintenance of up-to-date trail and accommodation information. After registering and being verified, hut workers can log into the platform to add or update information about their assigned huts, including uploading pictures and describing the facilities available. They can also monitor and report on the condition of nearby trails, ensuring hikers receive current information.\\\n",
    "Hut workers play a vital role in providing situational updates for hikers. For instance, if a nearby trail is impacted by severe weather or physical obstructions, they can communicate these conditions through the platform. This enhances the safety and preparedness of all hikers relying on the platform.\"\n",
    "\n",
    "\n",
    "user_instruction = f\"\"\"     \"\"\"\n",
    "\n",
    "\n",
    "prompt_router = f\"\"\"    \"\"\"\n",
    "\n",
    "\n",
    "#the response here will be only used for guiding the generation of the next prompt.\n",
    "#it must be one of two alternatives: \"Use Cases\" or \"Class Diagram\"\n",
    "response = ask_llama(prompt_router, maxl = 2000)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Task-Specific LLM - Generate Output\n",
    "The second LLM agent, based on the decision of the router, will either:\n",
    "\n",
    "- Generate use cases, or\n",
    "- Generate a class diagram\n",
    "\n",
    "In use case diagram design, the primary components typically include actors, which are entities interacting with the system, and use cases, which represent the goals or tasks the actors want to achieve. The diagram focuses on the interactions between these actors and the system, illustrating the functional requirements of the system from a user perspective. For this simplified example, we are focusing only on user-goal use cases (i.e., main functions of the system).\n",
    "\n",
    "In class diagram design, typically, the primary elements extracted are classes, their attributes, methods, and the relationships between them. Classes represent entities within the system, and attributes define their properties or characteristics. Methods outline the actions or operations that can be performed on or by a class. Additionally, relationships like associations, inheritance, and dependencies are represented to show how different classes interact with one another. For this simplified example, we are focusing only on the classes, leaving the recognition of individual attributes to other prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#remove all non textual characters from the response\n",
    "fixed_response = \"\"\n",
    "\n",
    "print(fixed_response)\n",
    "\n",
    "\n",
    "if (fixed_response == \"Use Cases\") :\n",
    "\n",
    "    prompt_use_cases = f\"\"\"    \"\"\"\n",
    "\n",
    "    response_uc = ask_llama(prompt_use_cases, maxl = 2000)\n",
    "\n",
    "    #format the response for readability\n",
    "    response = \"\"\n",
    "\n",
    "\n",
    "elif (fixed_response == \"Class Diagram\") :\n",
    "\n",
    "    prompt_class_diagram = f\"\"\"    \"\"\"\n",
    "\n",
    "    response_cd = ask_llama(prompt_class_diagram, maxl = 2000)\n",
    "\n",
    "    #format the response for readability\n",
    "    response = \"\"\n",
    "\n",
    "\n",
    "else : \n",
    "\n",
    "    print(\"Unrecognized command from the user\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reasoning\n",
    "\n",
    "Now reason about the following steps:\n",
    "- How can I evaluate the results? \n",
    "- How can I extend the prompts to provide other aspects of class and uml diagrams?\n",
    "- Try to execute the prompts with the ChatGPT engine. What are your results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
